{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from urllib.parse import quote\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "9xDdiMru0M3T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8EntN9niqY9i"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(1)"
      ],
      "metadata": {
        "id": "1kUaURtvk0Zg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/1923_dramalist.csv').iloc[:,1:]\n",
        "df.loc[df['작품명'] == '멀리서 보는 푸른 봄', '작품명'] = '멀리서 보면 푸른 봄'\n",
        "drama_list = df['작품명'].tolist()\n",
        "drama_list.extend(['에이틴', '에이틴 2'])"
      ],
      "metadata": {
        "id": "S07jN0ZIikwu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta1=pd.DataFrame()\n",
        "\n",
        "for name in tqdm(drama_list):\n",
        "  time.sleep(0.2)\n",
        "  title = pd.DataFrame({\"작품명\":[name]})\n",
        "  try:\n",
        "\n",
        "    url = f\"https://ko.wikipedia.org/wiki/{name}_(드라마)\"\n",
        "    encoded_url = quote(url, safe=':/_')\n",
        "    tables = pd.read_html(encoded_url)\n",
        "\n",
        "    # 수정 )) 이렇게 해야 다음으로 넘어갈 수 있는데 제가 실수했습니다. 아래의 try는 굳이 바꿀 필요 없어서 냅뒀어요.\n",
        "    for i in tables:\n",
        "      if i.iloc[2,0] == '장르' or i.iloc[1,0] == '장르':\n",
        "        table = i\n",
        "        break\n",
        "\n",
        "    table = table[0:].dropna().T\n",
        "    table.columns = table.iloc[0]\n",
        "    table = table[1:]\n",
        "\n",
        "    desired = ['작품명', '장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']\n",
        "\n",
        "    for col in desired:\n",
        "      if col not in table.columns:\n",
        "        table[col] = np.nan\n",
        "\n",
        "    table = table[['장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']].reset_index(drop = True)\n",
        "\n",
        "    table = pd.concat([title,table],axis=1)\n",
        "\n",
        "    # 이전 이후 드라마\n",
        "    df3 = pd.DataFrame()\n",
        "    for i in tables:\n",
        "      try:\n",
        "        if i.columns[0][1] == '이전 작품':\n",
        "          df3 = i\n",
        "          df3.columns = ['이전', '현재', '다음']\n",
        "          break\n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "    table = pd.concat([table, df3], axis=1)\n",
        "\n",
        "  except Exception:\n",
        "\n",
        "    try:\n",
        "      url = f\"https://ko.wikipedia.org/wiki/{name}\"\n",
        "      encoded_url = quote(url, safe=':/_')\n",
        "      tables = pd.read_html(encoded_url)\n",
        "      table = tables[0]\n",
        "\n",
        "      table = table[0:].dropna().T\n",
        "      table.columns = table.iloc[0]\n",
        "      table = table[1:]\n",
        "\n",
        "      desired = ['작품명', '장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']\n",
        "\n",
        "      for col in desired:\n",
        "        if col not in table.columns:\n",
        "          table[col] = np.nan\n",
        "\n",
        "      table = table[['장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']].reset_index(drop = True)\n",
        "\n",
        "      table = pd.concat([title,table],axis=1)\n",
        "\n",
        "      # 이전 이후 드라마\n",
        "      df3 = pd.DataFrame()\n",
        "      for i in tables:\n",
        "        try:\n",
        "          if i.columns[0][1] == '이전 작품':\n",
        "            df3 = i\n",
        "            df3.columns = ['이전', '현재', '다음']\n",
        "            break\n",
        "        except Exception:\n",
        "          pass\n",
        "\n",
        "      table = pd.concat([table, df3], axis=1)\n",
        "\n",
        "    except Exception as e:\n",
        "      table = title\n",
        "      print(name, e)\n",
        "\n",
        "  meta1=pd.concat([meta1,table],ignore_index=True) # concat 함수 내부 meta -> meta1\n"
      ],
      "metadata": {
        "id": "ZqqN2QIMsC6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67c2cfe-8277-4be2-f945-6dbc3b8e4176"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/422 [00:01<04:09,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          작품명\n",
            "0  너를 싫어하는 방법 HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 6/422 [00:03<04:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           작품명\n",
            "0  각색은 이미 시작됐다 HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/422 [00:05<04:02,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             작품명\n",
            "0  개같다 거지같다 아름답다 HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 94/422 [00:40<01:58,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              작품명\n",
            "0  에이틴 / 에이틴 시즌 2 HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 213/422 [01:26<01:32,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        작품명\n",
            "0  아이를 찾습니다 HTTP Error 404: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 422/422 [02:53<00:00,  2.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = meta1[meta1['장르'].isna()][\"작품명\"].unique().tolist()\n",
        "print(errors)\n",
        "## 코드를 약간 수정한 결과 에러리스트가 대폭 감소하였습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYw4zyS1Ayjo",
        "outputId": "37b43c22-02cd-406e-89e3-877000eb0610"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['신비아파트 외전: 기억, 하리 2', nan, '너를 싫어하는 방법', '각색은 이미 시작됐다', '반야', '개같다 거지같다 아름답다', '빅이슈', '인서울 - 내가 독립하는 유일한 방법', '에이틴 / 에이틴 시즌 2', '엑스가리온', '터치', '나의 위험한 아내', '트웬티트웬티', '하이에나', '바람과 구름과 비', '행복의 진수', '외출', '악의 꽃', '괴물', '아이를 찾습니다', '언더커버', '지리산', '내일', '아직 최선을 다하지 않았을 뿐', '이브', '괴이', '블라인드', '장미맨션', '치얼 업', '커튼 콜', '결혼백서', '아일랜드']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta1 = meta1.drop('현재', axis = 1)\n",
        "meta1 = meta1.drop([37,47,48,49,372]) # 외국작품인 리갈하이, 연예인매니저로 살아남기, 파고 삭제"
      ],
      "metadata": {
        "id": "Jr7-MLOFvO0s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 결과 어차피 안 나오는 것들은 배제하였습니다.\n",
        "error_list = ['빅이슈 (2019년 드라마)', '터치 (2020년 드라마)', '나의 위험한 아내 (대한민국의 드라마)', '트웬티 트웬티', '하이에나 (2020년 드라마)', '바람과 구름과 비 (2020년 드라마)',\n",
        "              '외출 (2020년 드라마)', '악의 꽃 (2020년 드라마)', '괴물 (2021년 드라마)', '언더커버 (2021년 드라마)', '지리산 (2021년 드라마)', '내일 (2022년 드라마)',\n",
        "              '이브 (2022년 드라마)', '블라인드 (2022년 드라마)', '커튼콜 (드라마)', '치얼업 (드라마)', '아일랜드 (2022년 드라마)', '리갈 하이 (2019년 드라마)', '연예인 매니저로 살아남기 (대한민국의 드라마)']\n"
      ],
      "metadata": {
        "id": "flFWx8eI5kIu"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사실 에러리스트를 만든 이상 try구문은 필요 없습니다. 에러리스트는 손수 구한 정확한 단어들이어서, 오류가 생기지 않거든요.\n",
        "# 그러나 이하에서는 코드를 더 안 건드리겠습니다. 맨 마지막 concat 안을 meta2로만 바꿨습니다.\n",
        "meta2=pd.DataFrame()\n",
        "\n",
        "for name in error_list:\n",
        "  title = pd.DataFrame({\"작품명\":[name]})\n",
        "  try:\n",
        "\n",
        "    url = f\"https://ko.wikipedia.org/wiki/{name}\"\n",
        "    encoded_url = quote(url, safe=':/_')\n",
        "    tables = pd.read_html(encoded_url)\n",
        "    table = tables[0]\n",
        "\n",
        "    table = table[0:].dropna().T\n",
        "    table.columns = table.iloc[0]\n",
        "    table = table[1:]\n",
        "\n",
        "    desired = ['작품명', '장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']\n",
        "\n",
        "    for col in desired:\n",
        "      if col not in table.columns:\n",
        "        table[col] = np.nan\n",
        "\n",
        "    table = table[['장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']].reset_index(drop = True)\n",
        "\n",
        "    table = pd.concat([title,table],axis=1)\n",
        "\n",
        "        # 이전 이후 드라마\n",
        "    for i in tables:\n",
        "      try:\n",
        "        if i.columns[0][1] == '이전 작품':\n",
        "          df3 = i\n",
        "          break\n",
        "      except Exception:\n",
        "        pass\n",
        "    df3.columns = ['이전', '현재', '다음']\n",
        "    table = pd.concat([table, df3.iloc[:, [0,2]]], axis=1)\n",
        "\n",
        "  except Exception:\n",
        "\n",
        "    try:\n",
        "      url = f\"https://ko.wikipedia.org/wiki/{name}_(드라마)\"\n",
        "      encoded_url = quote(url, safe=':/_')\n",
        "      tables = pd.read_html(encoded_url)\n",
        "      table=tables[0]\n",
        "\n",
        "      table = table[0:].dropna().T\n",
        "      table.columns = table.iloc[0]\n",
        "      table = table[1:]\n",
        "\n",
        "      desired = ['작품명', '장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']\n",
        "\n",
        "      for col in desired:\n",
        "        if col not in table.columns:\n",
        "          table[col] = np.nan\n",
        "\n",
        "      table = table[['장르', '방송 채널', '방송 기간', '방송 시간', '방송 분량', '방송 횟수', '기획', '책임프로듀서', '프로듀서', '제작사', '연출', '각본', '출연자']].reset_index(drop = True)\n",
        "\n",
        "      table = pd.concat([title,table],axis=1)\n",
        "\n",
        "            # 이전 이후 드라마\n",
        "      for i in tables:\n",
        "        try:\n",
        "          if i.columns[0][1] == '이전 작품':\n",
        "            df3 = i\n",
        "            break\n",
        "        except Exception:\n",
        "          pass\n",
        "      df3.columns = ['이전', '현재', '다음']\n",
        "      table = pd.concat([table, df3.iloc[:, [0,2]]], axis=1)\n",
        "\n",
        "    except Exception:\n",
        "      table = title\n",
        "\n",
        "  meta2=pd.concat([meta2,table],ignore_index=True)\n"
      ],
      "metadata": {
        "id": "VteWCq4v5K35"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta = pd.concat([meta1, meta2], ignore_index = True)\n",
        "meta = meta[~meta['작품명'].isna()].reset_index(drop = True)"
      ],
      "metadata": {
        "id": "caXbvmscNESG"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta.to_csv('메타데이터.csv', index=False, encoding='utf-8-sig')\n",
        "# files.download('미니시리즈_메타데이터.csv')"
      ],
      "metadata": {
        "id": "OpYXwCF8DHg4"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}